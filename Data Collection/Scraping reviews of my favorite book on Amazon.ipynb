{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59a962c",
   "metadata": {},
   "source": [
    "<b>Scraping reviews of my favourite book on Amazon</b> https://www.natasshaselvaraj.com/web-scraping/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331a7f5",
   "metadata": {},
   "source": [
    "In this tutorial, I will walk you through all the steps I took to scrape the book reviews on Amazon. I will use two Python libraries to do this - BeautifulSoup and Selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352ff31",
   "metadata": {},
   "source": [
    "<b> First, import the following packages: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e727e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6080546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: crayons in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.22.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dharmender\\appdata\\roaming\\python\\python37\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dharmender\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453fec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import io\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests,json, re\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba9c06",
   "metadata": {},
   "source": [
    "Now, we can use the Selenium web driver to automatically download the first 4 pages of the site that we want to scrape.\n",
    "\n",
    "First, we can create a folder to save the HTML files in. Then, we define the path in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9290e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path you want to save the HTML files in\n",
    "\n",
    "path = 'C:/Users/Dharmender/Desktop/ML_Learning/ML_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0aca5",
   "metadata": {},
   "source": [
    "Next, we can loop through the number of pages we want to scrape. In our case, its page 1 to page 5.\n",
    "\n",
    "Then, we can create a webdriver object, get all the pages we want to scrape and save the pages in our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88a016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fea8eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "There is no [win32] chromedriver for browser 92.0.4515 in cache\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/92.0.4515.107/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\Dharmender\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107]\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\Dharmender\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\Dharmender\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\Dharmender\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5) :\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = 'https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/product-reviews/1492032646/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews='+str(i)\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # save all 50 files in your path\n",
    "    \n",
    "    with io.open(path+\"amazon_page_\"+str(i)+\".html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aac362",
   "metadata": {},
   "source": [
    "After saving all 4 pages into our local directory, we can start with the web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c434c90",
   "metadata": {},
   "source": [
    "<b> Lets start with scraping one web page first: </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7266cf",
   "metadata": {},
   "source": [
    "To scrape it, we need to look at the HTML structure of the page. Right click on the review and click on \"inspect.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fd407",
   "metadata": {},
   "source": [
    "We can see that all the review text is wrapped in a span class called \"a-size-base review-text review-text-content.\"\n",
    "\n",
    "This is the element we need to extract when scraping reviews.\n",
    "\n",
    "To do this, you first need to open one of the pages you saved previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56832e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the first page you saved\n",
    "\n",
    "file = open(path+'amazon_page_1'+'.html',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bab55",
   "metadata": {},
   "source": [
    "Then, create a BeautifulSoup object to collect all the HTML code of that page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa939a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(file, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6cfea",
   "metadata": {},
   "source": [
    "Now, grab the 'span' class we found earlier using BeautifulSoup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbdb41",
   "metadata": {},
   "source": [
    "This code will render output that looks like this (it should show you around 10 reviews since you are only scraping the first page):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a3a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  I've read all of the predominant machine learning related python books and this one is by far the best one. I was excited to see the second edition of this book come out. It is packed with new information (1.5x the length of the first edition) and updated for TensorFlow 2. I have the Kindle edition and find it very helpful to highlight key points. I look forward to receiving the print edition as well once it is released.EDIT: Just received the print edition of the book and it's in color! The first edition wasn't. This is a pleasant surprise as it makes it easier to read with various charts and graphics.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  While I enjoy learning from this book, the math font in kindle edition is a mess which makes the reading unpleasant. I know to some this probably shouldn't be a deal breaker but for someone who wants to move from hard copy to kindle, it was a disappointment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  This book gives you a hands-on approach to learning by doing. As opposed to the trendy deep learning books that dive deep into the weeds from the start, this book starts with the more traditional ML approaches (the Scikit-learn part) giving you a great deal of context and practical tools for solving all kinds of problems. Only after does he transition into deep learning concepts, giving you both a great overview and the background to understand when and where to apply the various techniques. Its code-focused so you'll have the option to run working code on real problems throughout the book.Most important for me, he focuses on explanation over hand-wavy equations that are rampant in other ML books. I say hand-wavy because they typically go like so: \"Here's a hard concept. Rather than explain it well, I'll give you some linear algebra and calculus equations, remind you that this is stuff you should have learned in high school, and then move on.\" Authors probably feel justified in doing this, but after reading a book like this you understand what they are really doing: Skipping the hard-part of breaking difficult concepts down into chunks that can be consumed by a competent programmer, who is perhaps not an expert in \"high school\" math. Moreover, this author does so without dumbing down the content.  That's the mark of someone who well understands both the content and the audience.This book is long and dense, and serves as both a guide and a reference. It is not a quick read / overview or light reading type book.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  This is an update for my previous review.Recently, I gave one star for the poor ebook experience but with author's comment I realized the publisher updated the ebook and now everything is great in the ebook.As the name suggests, the book gives you a really hands-on experience on machine learning. This covers most of the recent main advancements in the field.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  I'm very pleased with this book. I enjoy the little bits of humor here and there, and it does a great job not glossing over important details that might be a stumbling block for someone. I'm quite comfortable with python however I appreciated that he did go into depth on setting up virtual environments and best practices. I remember years back when I was starting that whole concept tripped me up so much, having this explained so well is going to save someone a lot of time. Also his code seems so far to be written in a very thoughtful way and has them all on github. He also goes into lots of gotchas and tips and tricks that just overall seem to add a certain maturity to his writing. He has obviously very well versed in machine learning.Overall I would recommend. It's been much more interesting than I expected.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Aurelien did it again!Whether you are a data scientist looking to start building predictive models in Python, or a software developer looking to become an ML engineer, look no further!The excellent balance between theory/background and implementation that was present in the first edition is kept, with the essential material additions made (e.g. the unsupervised learning in the \"classical ML\" part, or the Keras API, which is quickly becoming the most popular way to use TensorFlow).Needless to say, the Jupyter notes accompanying each chapter are more than helpful.Also, as a cherry on top, the illustrations in the printed version are now in color, which makes it even easier to read.In summary, this book is an absolute must-have for a Python-rooted data scientist  / ML engineer!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  The book was worth the wait!  The publication quality of the print edition is great.  Love the color illustrations.  The one thing that I miss is that having bought the print edition, it would be sweet to have an offer to acquire the electronic edition at a reduced price but since Amazon now seems to be handling O'Reilly book sales and probably wants to sell as many Kindle editions as possible, a PDF copy of Hands-On Machine Learning, 2nd Ed., does not seem to be in my future at a bargain price.  My review is preliminary - I've read bits of the online draft version-and the clarity and superb organization of Géron's writing convinced me that I wanted a finished copy of the book.  My current avocational interest is Reinforcement Learning and Géron gives an excellent overview - to dive deep, one would probably still want to refer to Sutton & Barto's 2nd Ed. book (available on Amazon or for free online) or David Silver's excellent 2015 UCL lectures, also available online..  I will slowly work my way through Géron's book in its entirety but my primary reason for owning the book is as a reference.  It makes a great roadmap to the current state of machine learning and, best of all, it makes learning about ML fun!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  I'm finishing up an MCS in Data Science from UIUC and I can tell you bar none that this book should be required reading in this subject. The required ML course at school was so confusing and they assumed WAY too much. Reading over the same topics in this book was like night and day in terms of explaining things in a way that makes sense. The images, graphs, and tables are clear and help a lot by providing visuals to the text explanation. I did notice a few typos but so far nothing critical. This is not a light read as it comes in at almost 800 pages but taking it model-by-model is easy to do.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  The Tokyo Olympics of 2020 got postponed to 2021. If there were a contest for best AI/ML book at the Olympics this year this book would have earned the gold medal ! I loved it so much that I read it at least twice, and each time I underlined/highlighted/took-notes. I love how lucidly the author explains concepts. He does an excellent job of explaining topics such as the model, the learning algorithm (also called the optimization algorithm), regularization hyperparameter, generalization etc. The examples are great and even if one does not know python programming it is easy to follow along. (I learned python a few months later, which made it even easier and more interesting to follow the examples in this and other books). While no one single book can teach one ML/AI, this book would make the Mount Rushmore of AI/ML books (along with (1) Intro to Statistical Learning by Hastie etc (2) Intro to Machine Learning by Alpaydin (3) Deep Learning by Goodfellow, Bengio etc). I highly recommend this book to anyone aspiring to get into the field of ML/AI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  This is the third book I've bought from this guy and every single time on the first coding example(and other examples) there are codes missing or he doesn't add codes that he has already spoken about, unlike the other books where he constantly repeats the same thing over and over but for some reason can seem to repeat the code. Sometimes he just forgets to put in a line of code.This book is free online I learned that after googling for the right code but still I prefer buying the book. Even so, he should really have someone else check his work. unlike the other books, he keeps up with where he puts his \"imports\" and \"from\" codes in his other books it was always where he starts using it which is bad coding those codes should be put at the top of all the line of codes for ease of finding and it was well structured for that I will give it three stars.Despite, having to look for missing code I did enjoy this book it did help to have resources from his other books. This isn't really a surprise because I've done it in college, but I did not expect to do it in the first example from a well-known author.If you're thinking of getting the book get it but only if you plan on using other resources that is if you are completely new to coding. I would like to add if it wasn't for StackOverflow and his community on GitHub I would have given it a one star. Just know once you get the code working you get the biggest satisfaction and you will keep pressing on. Good luck during this pandemic coders\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find('div',{'id':'cm_cr-review_list'}):\n",
    "        review = i.find('span',{'class':'a-size-base review-text review-text-content'})\n",
    "        \n",
    "        if review is not None:\n",
    "                print(review.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc6fa8",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "The code works, and we have grabbed all the reviews from the first page and printed them out.\n",
    "\n",
    "Now, we just need to loop through all 4 pages and do the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526457da",
   "metadata": {},
   "source": [
    "Looping through all the pages and collecting reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d147a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list\n",
    "rev = [] \n",
    "\n",
    "# loop through all 4 pages\n",
    "for pages in range(1,5):\n",
    "    file = open(path+'amazon_page_'+str(pages)+'.html',encoding='utf-8')\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    \n",
    "    # find the reviews\n",
    "    for i in soup.find('div',{'id':'cm_cr-review_list'}):\n",
    "        review = i.find('span',{'class':'a-size-base review-text review-text-content'})\n",
    "        \n",
    "        # append reviews to list\n",
    "        if review is not None:\n",
    "            rev.append(review.text)\n",
    "        else:\n",
    "            rev.append('-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4007430",
   "metadata": {},
   "source": [
    "That's all!\n",
    "\n",
    "Once we're done running this block of code, all the saved reviews will be saved in the list 'rev' that we initialized.\n",
    "\n",
    "Now, all we need to do is turn that list into a Pandas data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8371d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'Reviews':rev})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e9d46",
   "metadata": {},
   "source": [
    "We can take a look at the head of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8c51931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n  I've read all of the predominant machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n  While I enjoy learning from this book, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n  This book gives you a hands-on approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n  This is an update for my previous review...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0                                                 -1\n",
       "1  \\n\\n  I've read all of the predominant machine...\n",
       "2  \\n\\n  While I enjoy learning from this book, t...\n",
       "3  \\n\\n  This book gives you a hands-on approach ...\n",
       "4  \\n\\n  This is an update for my previous review..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f6ca69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76336fbe",
   "metadata": {},
   "source": [
    "All the reviews we scraped are in there.\n",
    "\n",
    "The data frame will have around 48 rows, but if you drop the '-1' character, you'd get around 40 rows.\n",
    "\n",
    "If you want to collect more reviews, all you need to do is scrape more pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5100c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
